{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# <div style=\"text-align: center; color: cyan\">Train</div>",
   "id": "41f3c8f5071ef78c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <div style=\"text-align: center; color: lime\">Imports</div>",
   "id": "1c492126ad507e8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:25:32.962934Z",
     "start_time": "2025-08-19T09:25:31.850243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ],
   "id": "d2afa60a64620442",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <div style=\"text-align: center; color: lime\">AutoGrad</div>",
   "id": "d79722b0b6889922"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:25:32.968866Z",
     "start_time": "2025-08-19T09:25:32.967006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor(3.0, requires_grad=True)\n",
    "b = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "y = a ** 2 + b"
   ],
   "id": "5df0e2427137d0cd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:25:32.987638Z",
     "start_time": "2025-08-19T09:25:32.972105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y.backward()\n",
    "\n",
    "print(\"dy/da: \", a.grad.item())  # d(a**2 + b)/da = 2*a ----a=3----> 6\n",
    "print(\"dy/db: \", b.grad.item())  # d(a**2+b)/db = 1"
   ],
   "id": "5b0033806f7226a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/da:  6.0\n",
      "dy/db:  1.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:25:33.222246Z",
     "start_time": "2025-08-19T09:25:33.217665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w = torch.tensor(5.0, requires_grad=True)  # weight\n",
    "b = torch.tensor(2.0, requires_grad=True)  # bias\n",
    "\n",
    "x = 2  # input\n",
    "y_true = 7  # true output\n",
    "\n",
    "y_hat = w * x + b  # prediction\n",
    "\n",
    "loss = (y_hat - y_true) ** 2  # calculate loss\n",
    "loss.backward()  # calculate gradients\n",
    "\n",
    "print(f\"d(loss)/dw: {w.grad.item()}\")\n",
    "print(f\"d(loss)/db: {b.grad.item()}\")\n",
    "\n"
   ],
   "id": "2fcefbab00107b31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d(loss)/dw: 20.0\n",
      "d(loss)/db: 10.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <div style=\"text-align: center; color: lime\">Loss Function</div>",
   "id": "6778923e34d658cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:25:34.036989Z",
     "start_time": "2025-08-19T09:25:34.034072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_true = torch.tensor([0, 1])\n",
    "y = torch.tensor([\n",
    "    [2.0, 8.0],\n",
    "    [5.0, 5.0],\n",
    "])\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss = loss_fn(y, y_true)\n",
    "\n",
    "print(loss.item())"
   ],
   "id": "eafce58a00b68a28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.347811460494995\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:25:34.618030Z",
     "start_time": "2025-08-19T09:25:34.612721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_true = torch.tensor([0, 1])\n",
    "y = torch.tensor([\n",
    "    [100.0, 0.0],\n",
    "    [0.0, 100.0]\n",
    "])\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss = loss_fn(y, y_true)\n",
    "\n",
    "print(loss.item())\n"
   ],
   "id": "cdc5f4a3441efd72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <div style=\"text-align: center; color: lime\">Optimizer</div>",
   "id": "8b78b41aac173a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:25:36.384171Z",
     "start_time": "2025-08-19T09:25:35.938402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = nn.Linear(4, 2)\n",
    "\n",
    "optimizer = Adam(model.parameters())"
   ],
   "id": "69771b27c08f485c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:25:36.511378Z",
     "start_time": "2025-08-19T09:25:36.504351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([\n",
    "    [1.0, 2.0, 3.0, 4.0],\n",
    "    [-1.0, -2.0, -3.0, -4.0],\n",
    "])  # simple data\n",
    "y_true = torch.tensor([0, 1])  # simple targe\n",
    "\n",
    "for step in range(10):\n",
    "    optimizer.zero_grad()  # clear the gradients\n",
    "\n",
    "    logits = model(x)  # make a prediction\n",
    "\n",
    "    loss = loss_fn(logits, y_true)  # calculate the loss\n",
    "    print(f\"step {step}, loss: {loss.item()}\")\n",
    "\n",
    "    loss.backward()  # calculate the gradients with respect to loss\n",
    "\n",
    "    optimizer.step()  # optimize the weights"
   ],
   "id": "58f4ac04d9393731",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 0.8765422701835632\n",
      "step 1, loss: 0.8651807308197021\n",
      "step 2, loss: 0.8539098501205444\n",
      "step 3, loss: 0.842731773853302\n",
      "step 4, loss: 0.8316479921340942\n",
      "step 5, loss: 0.8206604719161987\n",
      "step 6, loss: 0.8097708225250244\n",
      "step 7, loss: 0.7989808320999146\n",
      "step 8, loss: 0.7882919311523438\n",
      "step 9, loss: 0.7777056097984314\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center\">\n",
    "\n",
    "<div>\n",
    "    @LiterallyTheOne â€” PhD Candidate in Artificial Intelligence\n",
    "</div>\n",
    "\n",
    "<a style=\"margin: 1em\" href=\"https://literallytheone.github.io\">\n",
    "https://literallytheone.github.io\n",
    "</a>\n",
    "\n",
    "</div>\n"
   ],
   "id": "8cd403317132c31b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
